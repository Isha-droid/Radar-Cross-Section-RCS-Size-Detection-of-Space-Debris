a=5
class(a)
a=5
a<-5L
class(a)
b
a
w<-5>2
w
class(w)
r="5"
r
class(r)
c = 3+5i
class(c)
c
install.packages("ggplot2")
library(ggplot2)
install.packages("dslabs")
library(dslabs)
vec = 25:100
vec
vec[vec>28 && vec<30]
vec[vec>28 & vec<30]
data.frame(name=c("Tendulkar","Ponting","Kallis","Dravid","Cook"), matches=c(200,168,166,164,161), innings=c(329,287,280,286,291), highestscore=c(248,257,224,270,294), avg=c(53.78,51.85,55.37,52.31,45.35))
match-stat <- data.frame(name=c("Tendulkar","Ponting","Kallis","Dravid","Cook"), matches=c(200,168,166,164,161), innings=c(329,287,280,286,291), highestscore=c(248,257,224,270,294), avg=c(53.78,51.85,55.37,52.31,45.35))
match_stat <- data.frame(name=c("Tendulkar","Ponting","Kallis","Dravid","Cook"), matches=c(200,168,166,164,161), innings=c(329,287,280,286,291), highestscore=c(248,257,224,270,294), avg=c(53.78,51.85,55.37,52.31,45.35))
match_stat
str(match_stat)
summary(match_stat)
match_stat$name
$name
summary(match_stat)
summary(match_stat)
head(match_stat)
head(match_stat,2)
head(match_stat,-2)
tail(match_stat,2)
tail(math_stat,-2)
tail(match_stat,-2)
nrow(match_stat)
ncol(match_stat)
`colnames<-`(match_stat)
colnames(match_stat)
match_stat[2][3]
match_stat
match_stat[2,3]
match_stat[3,c(1,3,5)]
match_stat[c(1,2),c(2,4)]
match_stat[,3]
match_stat
match_stat[4,]
match_stat
match_stat$half_cent <- c(68,62,58,63,57)
match_stat$cent <- c(51,41,45,36,33)
match_stat
new_match_stat <- (name=c("Sangakkara","Lara"), matches=c(134,1310), innings=c(233,232), highestscore=c(319,400), avg=c(57.40,52.80), half_cent=c(52,48), cent=c(38,34))
new_match_stat <- (name=c("Sangakkara","Lara"), matches=c(134,131), innings=c(233,232), highestscore=c(319,400), avg=c(57.40,52.80), half_cent=c(52,48), cent=c(38,34))
new_match_stat <- data.frame(name=c("Sangakkara","Lara"), matches=c(134,131), innings=c(233,232), highestscore=c(319,400), avg=c(57.40,52.80), half_cent=c(52,48), cent=c(38,34))
match_stat<-rbind(match_stat,new_match_stat)
match_stat
match_stat[,-7]
match_stat <- match_stat[,-7]
match_stat
match_stat[1,4]
match_stat[7,c(1,5)]
match_stat[match_atat$name="Tendulkar",4]
match_stat[match_stat$name="Tendulkar",4]
match_stat[match_stat$name=="Tendulkar",4]
match_stat[match_stat$highestscore.max(),4]
match_stat[max(match_stat$highestscore),4]
match_stat[max(match_stat$highestscore),1,5]
match_stat[match_stat$highestscore==max(match_stat$highestscore),1,5]
match_stat[match_stat$highestscore==max(match_stat$highestscore),c(1,5)]
match_stat[match_stat$highestscore == (match_stat$highestscore > 250), c(1,2,3,5)]
match_stat[match_stat$highestscore > 250, c(1,2,3,5)]
row.names(match_stat[match_stat$highestscore >= 270])
row.names(match_stat[match_stat$highestscore >= 270,])
as.integer(row.names(match_stat[match_stat$highestscore >= 270,]))
which(match_stat$highestscore >= 270)
match_stat[match_stat$name == "Tendulkar",5] = 201
match_stat
library(ggplot2)
svm_linear;
# Load the Dataset ----
data = read.csv("space_decay.csv");
source("F:/Data Science/CP/LR.R")
install.packages("class")
setwd("F:/Data Science/CP")
# Load the Dataset ----
d <- read.csv("Final_Processed_Data.csv");
View(d)
source("F:/Data Science/CP/FinalTraining.R")
View(test_data)
# Majority Based Ensemble Classification (Voting Based) ----
cat("\nMajority Ensembling \n");
# Adding the predictions from different models in test_preds
test_preds <- test_data[,c(11,12,13,14,15,16)];
# Calculating the max occuring predictions row wise and storing it in max_preds column
test_preds$max_pred <- apply(test_preds,1,function(row){
tbl = table(row)
names(tbl)[which.max(tbl)]
});
# Adding RCS_SIZE Column to test_preds
test_preds$RCS_SIZE = test_data$RCS_SIZE;
# Convert max_preds to factor
test_preds$max_pred = factor(test_preds$max_pred);
# Deriving Confusion Matrix
ensembled_cm <- confusionMatrix(test_preds$RCS_SIZE, test_preds$max_pred);
# Show confusion matrix in table format
levels <- c("LARGE","MEDIUM","SMALL");
cmt_en <- table(factor(test_preds$RCS_SIZE, levels = levels), factor(test_preds$max_pred, levels = levels), dnn = c("Actual","Predicted"));
#Calculate confusino matrix values for each class
tplarge_en = cmt_en["LARGE","LARGE"];
fnlarge_en = sum(cmt_en["LARGE",c('MEDIUM','SMALL')]);
fplarge_en = sum(c(cmt_en["MEDIUM","LARGE"], cmt_en["SMALL","LARGE"]));
tnlarge_en = sum(c(sum(cmt_en["MEDIUM",c('MEDIUM','SMALL')]),sum(cmt_en["SMALL",c('MEDIUM', 'SMALL')])));
tpmedium_en = cmt_en["MEDIUM","MEDIUM"];
fnmedium_en = sum(cmt_en["MEDIUM",c('LARGE','SMALL')]);
fpmedium_en = sum(c(cmt_en["LARGE","MEDIUM"], cmt_en["SMALL","MEDIUM"]));
tnmedium_en = sum(c(sum(cmt_en["LARGE",c('LARGE','SMALL')]), sum(cmt_en["SMALL",c('LARGE','SMALL')])));
tpsmall_en = cmt_en["SMALL","SMALL"];
fnsmall_en = sum(cmt_en["SMALL",c('LARGE','MEDIUM')]);
fpsmall_en = sum(c(cmt_en["LARGE","SMALL"], cmt_en["MEDIUM","SMALL"]));
tnsmall_en = sum(c(sum(cmt_en["LARGE",c('LARGE','MEDIUM')]), sum(cmt_en["MEDIUM",c('LARGE','MEDIUM')])));
# Extracting performance metrics
ensembled_acc <- ensembled_cm$overall['Accuracy'];
P_large_en <- tplarge_en/(tplarge_en+fplarge_en);
P_medium_en <- tpmedium_en/(tpmedium6+fpmedium_en);
P_small_en <- tpsmall_en/(tpsmall_en+fpsmall_en);
R_large_en = tplarge_en/(tplarge_en+fnlarge_en);
R_medium_en = tpmedium_en/(tpmedium_en+fnmedium_en);
R_small_en = tpsmall_en/(tpsmall_en+fnsmall_en);
f1_large_en = 2*(P_large_en*R_large_en)/(P_large_en+R_large_en);
f1_medium_en = 2*(P_medium_en*R_medium_en)/(P_medium_en+R_medium_en);
f1_small_en = 2*(P_small_en*R_small_en)/(P_small_en+R_small_en);
S_large_en = tnlarge_en/(tnlarge_en+fplarge_en);
S_medium_en = tnmedium_en/(tnmedium_en+fpmedium_en);
S_small_en = tnsmall_en/(tnsmall_en+fpsmall_en);
# Printing them
cat("\nAccuraccy of Ensembled Data : ",ensembled_acc);
print(paste("Precision Large:",P_large_en));
print(paste("Precision Medium:",P_medium_en));
print(paste("Precision Small:",P_small_en));
print(paste("Recall Large:",R_large_en));
print(paste("Recall Medium:",R_medium_en));
print(paste("Recall Small:",R_small_en));
print(paste("F1 Score Large:",f1_large_en));
print(paste("F1 Score Medium:",f1_medium_en));
print(paste("F1 Score Small:",f1_small_en));
print(paste("Specificity Large:",S_large_en));
print(paste("Specificity Medium:",S_medium_en));
print(paste("Specificity Small:",S_small_en));
# ROC and AUC plots for all algorithms combined ----
# Create ROC curve object for each class of GBM, RF and MLR
roc_curve_small1 <- roc(ifelse(test_data$RCS_SIZE == "SMALL", 1, 0), predictions1[, "SMALL"])
roc_curve_medium1 <- roc(ifelse(test_data$RCS_SIZE == "MEDIUM", 1, 0), predictions1[, "MEDIUM"])
roc_curve_large1 <- roc(ifelse(test_data$RCS_SIZE == "LARGE", 1, 0), predictions1[, "LARGE"])
roc_curve_small2 <- roc(ifelse(test_data$RCS_SIZE == "SMALL", 1, 0), predictions2[, "SMALL"])
roc_curve_medium2 <- roc(ifelse(test_data$RCS_SIZE == "MEDIUM", 1, 0), predictions2[, "MEDIUM"])
roc_curve_large2 <- roc(ifelse(test_data$RCS_SIZE == "LARGE", 1, 0), predictions2[, "LARGE"])
roc_curve_small3 <- roc(ifelse(test_data$RCS_SIZE == "SMALL", 1, 0), predictions3[, "SMALL"])
roc_curve_medium3 <- roc(ifelse(test_data$RCS_SIZE == "MEDIUM", 1, 0), predictions3[, "MEDIUM"])
roc_curve_large3 <- roc(ifelse(test_data$RCS_SIZE == "LARGE", 1, 0), predictions3[, "LARGE"])
# Plot ROC curves for each class GBM and RF
plot(roc_curve_small1, main = "ROC Curves (GBM, RF, MLR)", col = "red", lwd = 2)
lines(roc_curve_medium1, col = "green", lwd = 2)
lines(roc_curve_large1, col = "blue", lwd = 2)
lines(roc_curve_small2, col = "yellow", lwd = 2)
lines(roc_curve_medium2, col = "brown", lwd = 2)
lines(roc_curve_large2, col = "magenta", lwd = 2)
lines(roc_curve_small3, col = "orange", lwd = 2)
lines(roc_curve_medium3, col = "purple", add = TRUE, lwd = 2)
lines(roc_curve_large3, col = "cyan", add = TRUE, lwd = 2)
# Add legend
legend("bottomright", legend = c("Small(GBM)", "Medium(GBM)", "Large(GBM)", "Small(RF)", "Medium(RF)", "Large(RF)", "Small(MLR)", "Medium(MLR)", "Large(MLR)"), col = c("red", "green", "blue", "yellow", "brown", "magenta", "orange", "purple", "cyan"), lwd = 2, cex=0.7)
# Create ROC curve object for each class of NB, SVM, DT
roc_curve_small4 <- roc(ifelse(test_data$RCS_SIZE == "SMALL", 1, 0), predictions4[, "SMALL"])
roc_curve_medium4 <- roc(ifelse(test_data$RCS_SIZE == "MEDIUM", 1, 0), predictions4[, "MEDIUM"])
roc_curve_large4 <- roc(ifelse(test_data$RCS_SIZE == "LARGE", 1, 0), predictions4[, "LARGE"])
roc_curve_small5 <- roc(ifelse(test_data$RCS_SIZE == "SMALL", 1, 0), probabilities[, "SMALL"])
roc_curve_medium5 <- roc(ifelse(test_data$RCS_SIZE == "MEDIUM", 1, 0), probabilities[, "MEDIUM"])
roc_curve_large5 <- roc(ifelse(test_data$RCS_SIZE == "LARGE", 1, 0), probabilities[, "LARGE"])
roc_curve_small6 <- roc(ifelse(test_data$RCS_SIZE == "SMALL", 1, 0), predictions6[, "SMALL"])
roc_curve_medium6 <- roc(ifelse(test_data$RCS_SIZE == "MEDIUM", 1, 0), predictions6[, "MEDIUM"])
roc_curve_large6 <- roc(ifelse(test_data$RCS_SIZE == "LARGE", 1, 0), predictions6[, "LARGE"])
# Plot ROC curves for each class GBM and RF
plot(roc_curve_small4, main = "ROC Curves (NB, SVM, DT)", col = "red", lwd = 2)
lines(roc_curve_medium4, col = "green", lwd = 2)
lines(roc_curve_large4, col = "blue", lwd = 2)
lines(roc_curve_small5, col = "yellow", lwd = 2)
lines(roc_curve_medium5, col = "brown", lwd = 2)
lines(roc_curve_large5, col = "magenta", lwd = 2)
lines(roc_curve_small6, col = "orange", lwd = 2)
lines(roc_curve_medium6, col = "purple", add = TRUE, lwd = 2)
lines(roc_curve_large6, col = "cyan", add = TRUE, lwd = 2)
# Add legend
legend("bottomright", legend = c("Small(NB)", "Medium(NB)", "Large(NB)", "Small(SVM)", "Medium(SVM)", "Large(SVM)", "Small(DT)", "Medium(DT)", "Large(DT)"), col = c("red", "green", "blue", "yellow", "brown", "magenta", "orange", "purple", "cyan"), lwd = 2, cex=0.7)
source("F:/Data Science/CP/FinalTraining.R")
# Load the Dataset ----
d <- read.csv("Final_Processed_Data.csv");
View(d)
source("F:/Data Science/CP/FinalTraining.R")
View(d)
str(d)
# Load the Dataset ----
d <- read.csv("Final_Processed_Data.csv");
# Install and load required packages ----
# if (!requireNamespace("caret", quietly = TRUE)){
#   install.packages("caret");
# }
#
# if (!requireNamespace("e1071", quietly = TRUE)){
#   install.packages("e1071");
# }
#
# if (!requireNamespace("randomForest", quietly = TRUE)){
#   install.packages("randomForest");
# }
#
# if (!requireNamespace("xgboost", quietly = TRUE)){
#   install.packages("xgboost");
# }
library(caret);
library(randomForest);
library(e1071);
library(pROC)
# Removing the least affecting columns after feature selection ----
d <- d[, -c(which(names(d) %in% c("OBJECT_AGE","CENT_FOCUS_DIST","OBJECT_TYPE")))];
# Converting categorical variables into factors ----
categorical_columns <- c(11);
d[, categorical_columns] <- lapply(d[, categorical_columns], as.factor);
# Shuffle data and split it for training and testing ----
set.seed(123); # for reproducibility
train_indices <- createDataPartition(d$RCS_SIZE, p = 0.8, list = FALSE); # 80% for training, 20% for testing
train_data <- d[train_indices, ];
test_data <- d[-train_indices, ];
# Create a training control object ----
ctrl = trainControl(method="repeatedcv", number = 10);
# Train the Gradient Boosting Machine (GBM) model ----
cat("\nGradient Boosting Machine (GBM) \n");
set.seed(123);
gbm_model = train(x = train_data[-c(11)], y = train_data$RCS_SIZE, method = "gbm", trControl=ctrl);
# Make predictions using the trained SVM model on test data
tp1 <- predict(gbm_model, test_data[, -c(11)]); # column 11 is the target variable
source("F:/Data Science/CP/Algorithms.R")
rf_model <- randomForest(RCS_SIZE~., data = train_data, ntree = 500);
# Make predictions using the trained SVM model on test data
tp2 <- predict(rf_model, test_data[, -c(14)]); # column 12 is the target variable
test_data$test_preds2 = tp2;
predictions2 <- predict(rf_model, test_data[, -c(11)], type = "prob")
